{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ab151d-9666-4c16-a86c-0df3ee26b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT STATEMENTS\n",
    "import selenium\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # supress scikit 'future warnings'\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import matplotlib         \n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import norm, kurtosis\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import stats\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "from dataclasses import dataclass\n",
    "random.seed(42)\n",
    "import torch\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "train_prefix = \"CIFAR-10-images/train/\"\n",
    "test_prefix = \"CIFAR-10-images/test/\"\n",
    "folder_name_keys = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "total_classes = 10\n",
    "images_per_class_train = 5000\n",
    "total_train_images = total_classes * images_per_class_train\n",
    "images_per_class_test = 1000\n",
    "total_test_images = total_classes * images_per_class_test\n",
    "image_h = 32\n",
    "image_w = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ebe3f25-0c19-418d-8158-4c1d4680bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEAVILY USED FUNCTIONS THROUGHOUT PROJECT\n",
    "def pad_number(num: int, length: int):\n",
    "    s = str(num)\n",
    "    while len(s) < length:\n",
    "        s = \"0\" + s\n",
    "    return s\n",
    "\n",
    "def create_grayscale_batch(train: bool, batch_folder_indexes: np.ndarray, batch_image_indexes: np.ndarray):\n",
    "    B = np.shape(batch_image_indexes)[0]\n",
    "    res_tensor = torch.zeros(B,1,image_h,image_w)\n",
    "    for i in range(B):\n",
    "        folder_index = batch_folder_indexes[i]\n",
    "        image_index = batch_image_indexes[i]\n",
    "        filepath = \"\"\n",
    "        if train:\n",
    "            filepath += train_prefix\n",
    "        else:\n",
    "            filepath += test_prefix\n",
    "        filepath += (folder_name_keys[folder_index] + \"/\" + pad_number(image_index,4) + \".jpg\")\n",
    "        img = io.imread(filepath, as_gray=True)\n",
    "        res_tensor[i][0] = torch.tensor(img)\n",
    "    return res_tensor\n",
    "\n",
    "def create_ground_truth_batch(batch_folder_indexes: np.ndarray):\n",
    "    return torch.tensor(batch_folder_indexes)\n",
    "    #return torch.nn.functional.one_hot(batch_folder_indexes, total_classes)\n",
    "\n",
    "def rank_approx(F: np.ndarray, rank_n: int):\n",
    "    # Input: F -> Convultional Filter to get the best approx\n",
    "    # Input: rank_n -> Compute rank-rank_n approx on F\n",
    "    # Returns f, g where fg^T is the best rank-rank_n approx for F\n",
    "    M, N = np.shape(F)\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "    U_up_to_rank = np.reshape(U[:,:rank_n], (M,rank_n))\n",
    "    S_up_to_rank = np.reshape(np.diag(S[:rank_n]), (rank_n,rank_n))\n",
    "    V_up_to_rank = np.reshape(V[:rank_n], (rank_n,N))\n",
    "    \n",
    "    f = np.matmul(U_up_to_rank, S_up_to_rank)\n",
    "    g = V_up_to_rank.T\n",
    "    \n",
    "    return f, g\n",
    "\n",
    "def conv_reg(F: np.ndarray, A: np.ndarray):\n",
    "    M_a, N_a = np.shape(A)\n",
    "    M_f, N_f = np.shape(F)\n",
    "    M_res = M_a - M_f + 1\n",
    "    N_res = N_a - N_f + 1\n",
    "    \n",
    "    res = np.zeros((M_res, N_res))\n",
    "    \n",
    "    for r in range(M_res):\n",
    "        for c in range(N_res):\n",
    "            curr_filter_result = np.sum(A[r:r+M_f,c:c+N_f] * F)\n",
    "            res[r][c] = curr_filter_result\n",
    "    \n",
    "    return res\n",
    "\n",
    "def conv_approx(F: np.ndarray, A: np.ndarray, rank_n: int):\n",
    "    M_a, N_a = np.shape(A)\n",
    "    M_f, N_f = np.shape(F)\n",
    "    M_res = M_a - M_f + 1\n",
    "    N_res = N_a - N_f + 1\n",
    "    \n",
    "    final_res = np.zeros((M_res, N_res))\n",
    "    f, g = rank_approx(F, rank_n)\n",
    "    \n",
    "    for i in range(rank_n):\n",
    "        left_matrix = np.zeros((M_res, M_a))\n",
    "        right_matrix = np.zeros((N_a, N_res))\n",
    "\n",
    "        for r in range(M_res):\n",
    "            left_matrix[r,r:r+M_f] = (f.T)[i]\n",
    "\n",
    "        for c in range(N_res):\n",
    "            right_matrix[c:c+N_f,c] = g[i]\n",
    "            \n",
    "        add_matrix = np.matmul(left_matrix, np.matmul(A, right_matrix))\n",
    "        final_res = final_res + add_matrix\n",
    "    \n",
    "    return final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44800af3-21e8-49c6-bbe4-ba256b7edbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_test\n",
      "[[2. 1.]\n",
      " [2. 1.]]\n",
      "Approx F_test with rank: 1\n",
      "[[2. 1.]\n",
      " [2. 1.]]\n",
      "FROB NORM OF DIFF: 1.961044852356119e-15\n",
      "\n",
      "F_test_2\n",
      "[[2.  1. ]\n",
      " [2.  1.1]]\n",
      "Approx F_test_2 with rank: 1\n",
      "[[1.97920426 1.03959153]\n",
      " [2.020372   1.0612152 ]]\n",
      "FROB NORM OF DIFF: 0.0626037711536505\n",
      "Approx F_test_2 with rank: 2\n",
      "[[2.  1. ]\n",
      " [2.  1.1]]\n",
      "FROB NORM OF DIFF: 1.6910413304902302e-15\n"
     ]
    }
   ],
   "source": [
    "# CELL TO VALIDATE THE RANK_APPROX FUNCTION WITH FEW EXAMPLES\n",
    "# NOTE THAT DUE TO FLOATING POINT ISSUES, THERE IS EXTREMELY SLIGHT\n",
    "# ERRORS WHICH IS ACCOUNTED FOR BY USING diff_norm <= 1e-12\n",
    "\n",
    "test = np.array([[2.0,1.0], [2.0,1.0]])\n",
    "f_test_res, g_test_res = rank_approx(test, 1)\n",
    "print(\"F_test\")\n",
    "print(test)\n",
    "print(\"Approx F_test with rank: 1\")\n",
    "f_approx = np.matmul(f_test_res, g_test_res.T)\n",
    "print(f_approx)\n",
    "diff_norm = np.linalg.norm(test - f_approx)\n",
    "print(\"FROB NORM OF DIFF: \" + str(diff_norm))\n",
    "assert diff_norm <= 1e-12\n",
    "\n",
    "test[1][1] += 0.1\n",
    "f_test_res_2, g_test_res_2 = rank_approx(test, 1)\n",
    "print(\"\\nF_test_2\")\n",
    "print(test)\n",
    "print(\"Approx F_test_2 with rank: 1\")\n",
    "f_approx = np.matmul(f_test_res_2, g_test_res_2.T)\n",
    "print(f_approx)\n",
    "diff_norm = np.linalg.norm(f_approx - test)\n",
    "print(\"FROB NORM OF DIFF: \" + str(diff_norm))\n",
    "assert diff_norm <= 0.07\n",
    "\n",
    "f_test_res_2, g_test_res_2 = rank_approx(test, 2)\n",
    "print(\"Approx F_test_2 with rank: 2\")\n",
    "f_approx = np.matmul(f_test_res_2, g_test_res_2.T)\n",
    "print(f_approx)\n",
    "diff_norm = np.linalg.norm(test - f_approx)\n",
    "print(\"FROB NORM OF DIFF: \" + str(diff_norm))\n",
    "assert diff_norm <= 1e-12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "385e722a-a5c9-49cf-af26-c2632643b74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROB NORM OF DIFF BETWEEN REG AND APPROX CONV WHERE EXACT APPROX IS POSSIBLE: 4.5114551590683366e-15\n"
     ]
    }
   ],
   "source": [
    "# CELL TO VALIDATE CONV_REG AND CONV_APPROX FUNCTIONS WITH AN EXAMPLE\n",
    "# THIS CELL CHECKS WHEN RANK OF F IS 1\n",
    "\n",
    "A = np.random.randn(10,10)\n",
    "test_f = np.array([[1.0,1.0], [1.0,1.0]])\n",
    "\n",
    "conv_reg_A = conv_reg(test_f, A)\n",
    "\n",
    "# Check ensuring conv_reg function is working properly\n",
    "for i in range(np.shape(conv_reg_A)[0]):\n",
    "    for j in range(np.shape(conv_reg_A)[1]):\n",
    "        check = A[i][j] + A[i][j+1] + A[i+1][j] + A[i+1][j+1]\n",
    "        assert check == conv_reg_A[i][j]\n",
    "        \n",
    "conv_approx_A_1 = conv_approx(test_f, A, 1)\n",
    "f, g = rank_approx(test_f, 1)\n",
    "diff_norm = np.linalg.norm(conv_approx_A_1 - conv_reg_A)\n",
    "print(\"FROB NORM OF DIFF BETWEEN REG AND APPROX CONV WHERE EXACT APPROX IS POSSIBLE: \" + str(diff_norm))\n",
    "\n",
    "# NOTE THAT DUE TO FLOATING POINT ERROR THERE MAY BE SLIGHT\n",
    "# ERRORS FROM THE EXACT BUT WITH SUCH A SMALL ERROR WE CAN\n",
    "# JUST CONSIDER THE MATRICES EQUAL AND THE FUNCTIONS VALID\n",
    "assert diff_norm <= 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc32f30b-942a-48d5-8edc-53bb5f19b6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROB NORM OF DIFF BETWEEN REG AND APPROX CONV WHERE EXACT APPROX IS POSSIBLE: 1.309556114533831e-14\n"
     ]
    }
   ],
   "source": [
    "# CELL TO VALIDATE CONV_REG AND CONV_APPROX FUNCTIONS WITH AN EXAMPLE\n",
    "# THIS CELL CHECKS WHEN RANK OF F IS 1\n",
    "\n",
    "A = np.random.randn(10,10)\n",
    "test_f = np.array([[1.0,1.0], [1.0,1.1]])\n",
    "\n",
    "conv_reg_A = conv_reg(test_f, A)\n",
    "\n",
    "# Check ensuring conv_reg function is working properly\n",
    "for i in range(np.shape(conv_reg_A)[0]):\n",
    "    for j in range(np.shape(conv_reg_A)[1]):\n",
    "        check = A[i][j] + A[i][j+1] + A[i+1][j] + A[i+1][j+1] * 1.1\n",
    "        assert check == conv_reg_A[i][j]\n",
    "        \n",
    "conv_approx_A_1 = conv_approx(test_f, A, 2)\n",
    "f, g = rank_approx(test_f, 2)\n",
    "diff_norm = np.linalg.norm(conv_approx_A_1 - conv_reg_A)\n",
    "print(\"FROB NORM OF DIFF BETWEEN REG AND APPROX CONV WHERE EXACT APPROX IS POSSIBLE: \" + str(diff_norm))\n",
    "\n",
    "# NOTE THAT DUE TO FLOATING POINT ERROR THERE MAY BE SLIGHT\n",
    "# ERRORS FROM THE EXACT BUT WITH SUCH A SMALL ERROR WE CAN\n",
    "# JUST CONSIDER THE MATRICES EQUAL AND THE FUNCTIONS VALID\n",
    "assert diff_norm <= 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1d43464-95a7-435b-8866-64c6f6877e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(torch.nn.Module):\n",
    "    def __init__(self, channel_count, classes_count):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(channel_count, channel_count, (5,5), padding = 'same')\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.pool1 = torch.nn.MaxPool2d((2,2), (2,2))\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(channel_count, channel_count, (5,5), padding = 'same')\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.pool2 = torch.nn.MaxPool2d((2,2), (2,2))\n",
    "        \n",
    "        in_flattened_size = int(image_h) * int(image_w)//16\n",
    "        out_flattened_size = in_flattened_size//2\n",
    "        self.linear1 = torch.nn.Linear(in_flattened_size, out_flattened_size)\n",
    "        self.activation3 = torch.nn.ReLU()\n",
    "        \n",
    "        self.linear2 = torch.nn.Linear(out_flattened_size, 10)\n",
    "        \n",
    "    def forward(self, batch_input):\n",
    "        batch_layer_1_res = self.pool1(self.activation1(self.conv1(batch_input)))\n",
    "        batch_layer_2_res = self.pool2(self.activation2(self.conv2(batch_layer_1_res)))\n",
    "        batch_layer_3_res = self.activation3(self.linear1(torch.flatten(batch_layer_2_res)))\n",
    "        res_logits = batch_layer_3_res\n",
    "        return res_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "459fec05-0b00-4d97-8c5f-97c9b53bc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 5\n",
    "LR_START = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_ROUNDS = total_train_images//BATCH_SIZE\n",
    "if total_train_images%BATCH_SIZE: \n",
    "    TRAIN_ROUNDS += 1\n",
    "TEST_ROUNDS = total_test_images//BATCH_SIZE\n",
    "if total_test_images%BATCH_SIZE: \n",
    "    TEST_ROUNDS += 1\n",
    "\n",
    "model = CNNModel(1, total_classes)\n",
    "adam_optimizer = torch.optim.Adam(model.parameters(), lr=LR_START)\n",
    "ceLoss = torch.nn.CrossEntropyLoss()\n",
    "loss_acc_history = np.zeros((6,E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76566877-684c-41d9-87eb-7a7dea24f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch: int):\n",
    "    order = np.arange(total_train_images, dtype = int)\n",
    "    np.random.shuffle(order)\n",
    "    folder_indexes_order = np.floor_divide(order, images_per_class_train)\n",
    "    image_indexes_order = order - (folder_indexes_order * images_per_class_train)\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for curr_round in range(TRAIN_ROUNDS):\n",
    "        start_index = curr_round * BATCH_SIZE\n",
    "        end_index = min(start_index + BATCH_SIZE, total_train_images)\n",
    "        batch_train_tensor = create_grayscale_batch(\n",
    "            True, \n",
    "            folder_indexes_order[start_index:end_index],\n",
    "            image_indexes_order[start_index:end_index]\n",
    "        )\n",
    "        batch_truth_tensor = create_ground_truth_batch(folder_indexes_order[start_index:end_index])\n",
    "\n",
    "        batch_res = model(batch_train_tensor)\n",
    "        loss = ceLoss(batch_res, batch_truth_tensor)\n",
    "\n",
    "        adam_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        adam_optimizer.step()\n",
    "\n",
    "        total_loss += float(loss)\n",
    "        total_correct += torch.sum(torch.argmax(batch_res, dim = 1).int() == batch_truth_tensor.int())\n",
    "        \n",
    "    epoch_acc = float(total_correct)/float(total_train_images)\n",
    "    loss_acc_history[0][epoch] = total_loss\n",
    "    loss_acc_history[1][epoch] = epoch_acc\n",
    "    print(\"POST EPOCH: \" + str(epoch) + \" train loss: \" + str(total_loss))\n",
    "    print(\"POST EPOCH: \" + str(epoch) + \" train accuracy: \" + str(epoch_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a47bb6-855d-4d03-bdf8-e26838202589",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4cb94-9194-4481-8aa3-b8492d75c6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
