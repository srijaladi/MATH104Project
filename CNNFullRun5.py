#IMPORT STATEMENTSimport seleniumimport numpy as npimport warningswarnings.filterwarnings('ignore')  # supress scikit 'future warnings'import pandas as pdfrom sklearn import preprocessingfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import MinMaxScalerfrom sklearn.linear_model import LogisticRegressionfrom sklearn.linear_model import LinearRegressionfrom sklearn.metrics import confusion_matrixfrom sklearn.model_selection import GridSearchCVfrom scipy.optimize import linear_sum_assignmentimport matplotlib         from matplotlib import pyplot as pltfrom scipy.stats import normfrom scipy.stats import norm, kurtosisfrom sklearn import linear_modelfrom sklearn.linear_model import Ridgefrom sklearn.metrics import mean_squared_errorfrom sklearn.ensemble import GradientBoostingRegressorfrom sklearn.preprocessing import PolynomialFeaturesfrom sklearn.pipeline import make_pipelinefrom sklearn.linear_model import LinearRegressionfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysisfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysisfrom sklearn import svmfrom sklearn.svm import SVCfrom sklearn.preprocessing import StandardScalerfrom sklearn.preprocessing import StandardScalerfrom sklearn.pipeline import make_pipelinefrom sklearn.ensemble import GradientBoostingClassifierfrom sklearn.ensemble import RandomForestClassifierfrom scipy import statsimport mathimport pickleimport randomimport copyimport itertoolsfrom dataclasses import dataclassrandom.seed(42)import torchfrom skimage import colorfrom skimage import ioimport timetrain_prefix = "CIFAR-10-images/train/"test_prefix = "CIFAR-10-images/test/"folder_name_keys = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]total_classes = 5images_per_class_train = 5000total_train_images = total_classes * images_per_class_trainimages_per_class_test = 1000total_test_images = total_classes * images_per_class_testimage_h = 32image_w = 32E = 250LR_START = 1e-3BATCH_SIZE = 64POOL_SIZE_PER = (2,2)POOL_STRIDE = (2,2)TRAIN_ROUNDS = total_train_images//BATCH_SIZEif total_train_images%BATCH_SIZE:     TRAIN_ROUNDS += 1TEST_ROUNDS = total_test_images//BATCH_SIZEif total_test_images%BATCH_SIZE:     TEST_ROUNDS += 1DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")# HEAVILY USED FUNCTIONS THROUGHOUT PROJECTdef pad_number(num: int, length: int):    s = str(num)    while len(s) < length:        s = "0" + s    return sdef create_grayscale_batch(train: bool, batch_folder_indexes: np.ndarray, batch_image_indexes: np.ndarray):    B = np.shape(batch_image_indexes)[0]        res_tensor = torch.tensor(np.zeros((B,1,image_h,image_w)), dtype = float).to(DEVICE)    for i in range(B):        folder_index = batch_folder_indexes[i]        image_index = batch_image_indexes[i]        filepath = ""        if train:            filepath += train_prefix        else:            filepath += test_prefix        filepath += (folder_name_keys[folder_index] + "/" + pad_number(image_index,4) + ".jpg")        img = io.imread(filepath, as_gray=True)        res_tensor[i][0] = torch.tensor(img)    return res_tensordef create_ground_truth_batch(batch_folder_indexes: np.ndarray):    return torch.tensor(batch_folder_indexes)    #return torch.nn.functional.one_hot(batch_folder_indexes, total_classes)def rank_approx(F: np.ndarray, rank_n: int):    # Input: F -> Convultional Filter to get the best approx    # Input: rank_n -> Compute rank-rank_n approx on F    # Returns f, g where fg^T is the best rank-rank_n approx for F    M, N = np.shape(F)    U,S,V = np.linalg.svd(F)    U_up_to_rank = np.reshape(U[:,:rank_n], (M,rank_n))    S_up_to_rank = np.reshape(np.diag(S[:rank_n]), (rank_n,rank_n))    V_up_to_rank = np.reshape(V[:rank_n], (rank_n,N))        f = np.matmul(U_up_to_rank, S_up_to_rank)    g = V_up_to_rank.T        return f, gdef conv_reg(F: np.ndarray, A: np.ndarray):    M_a, N_a = np.shape(A)    M_f, N_f = np.shape(F)    M_res = M_a - M_f + 1    N_res = N_a - N_f + 1        res = np.zeros((M_res, N_res))        for r in range(M_res):        for c in range(N_res):            curr_filter_result = np.sum(A[r:r+M_f,c:c+N_f] * F)            res[r][c] = curr_filter_result        return resdef conv_approx(F: np.ndarray, A: np.ndarray, rank_n: int):    M_a, N_a = np.shape(A)    M_f, N_f = np.shape(F)    M_res = M_a - M_f + 1    N_res = N_a - N_f + 1        final_res = np.zeros((M_res, N_res))    f, g = rank_approx(F, rank_n)        for i in range(rank_n):        left_matrix = np.zeros((M_res, M_a))        right_matrix = np.zeros((N_a, N_res))        for r in range(M_res):            left_matrix[r,r:r+M_f] = (f.T)[i]        for c in range(N_res):            right_matrix[c:c+N_f,c] = g[:,i]                    add_matrix = np.matmul(left_matrix, np.matmul(A, right_matrix))        final_res = final_res + add_matrix        return final_resdef conv_approx_given(A: np.ndarray, left_matrices: np.ndarray, right_matrices: np.ndarray):    final_res = np.zeros((np.shape(left_matrices)[1], np.shape(right_matrices)[2]))        for i in range(len(left_matrices)):        left_matrix = left_matrices[i]        right_matrix = right_matrices[i]        add_matrix = np.matmul(left_matrix, np.matmul(A, right_matrix))        final_res = final_res + add_matrix            return final_resdef conv_approx_create_matrices(F: np.ndarray, h_use: int, w_use: int, rank_n: int):    if rank_n <= 0:        return np.zeros(image_h), np.zeros(image_w)        M_a = h_use + 4    N_a = w_use + 4    M_f, N_f = np.shape(F)    M_res = M_a - M_f + 1    N_res = N_a - N_f + 1        f, g = rank_approx(F, rank_n)    left_matrices = np.zeros((rank_n, M_res, M_a))    right_matrices = np.zeros((rank_n, N_a, N_res))        for i in range(rank_n):        left_matrix = np.zeros((M_res, M_a))        right_matrix = np.zeros((N_a, N_res))        for r in range(M_res):            left_matrix[r,r:r+M_f] = (f.T)[i]        for c in range(N_res):            right_matrix[c:c+N_f,c] = g[:,i]                 left_matrices[i] = left_matrix        right_matrices[i] = right_matrix        return left_matrices, right_matricesdef np_relu(x: np.ndarray):    return np.clip(x, a_min = 0, a_max = np.inf)def np_pool(x: np.ndarray, size_per: tuple, stride: tuple):    x_tensor = torch.zeros(1,*np.shape(x))    x_tensor[0] = torch.tensor(x)    pooled = torch.nn.functional.max_pool2d(x_tensor, kernel_size = size_per, stride = stride)    return np.squeeze(pooled.numpy())def np_linear(x: np.ndarray, weights: np.ndarray):    return np.matmul(weights, np.reshape(x, (-1,1)))def np_process_image(x: np.ndarray,                      F1: np.ndarray, F2: np.ndarray,                      B1: float, B2: float,                     left_matrices_1: np.ndarray, right_matrices_1: np.ndarray,                      left_matrices_2: np.ndarray, right_matrices_2: np.ndarray,                     size_per: tuple, stride: tuple,                      w1: np.ndarray, w2: np.ndarray,                      lb1: float, lb2: float,                      rank_n: int):    x = np.pad(x, (2,2), 'constant', constant_values = 0)    if rank_n:        conv1_res = conv_approx_given(x, left_matrices_1, right_matrices_1)    else:        conv1_res = conv_reg(F1, x)    conv1_res = conv1_res + B1    activation1_res = np_relu(conv1_res)    pool1_res = np_pool(activation1_res, size_per, stride)    pool1_res = np.pad(pool1_res, (2,2), 'constant', constant_values = 0)     if rank_n:        conv2_res = conv_approx_given(pool1_res, left_matrices_2, right_matrices_2)    else:        conv2_res = conv_reg(F2, pool1_res)    conv2_res = conv2_res + B2    activation2_res = np_relu(conv2_res)    pool2_res = np_pool(activation2_res, size_per, stride)        #print(conv2_res)    #print(activation2_res)    #print(pool2_res)    linear1_res = np_linear(pool2_res, w1) + lb1    activation3_res = np_relu(linear1_res)        linear2_res = np_linear(activation3_res, w2) + lb2    final_logits = np.reshape(linear2_res, (-1,))        return final_logits# CELL TO VALIDATE THE RANK_APPROX FUNCTION WITH FEW EXAMPLES# NOTE THAT DUE TO FLOATING POINT ISSUES, THERE IS EXTREMELY SLIGHT# ERRORS WHICH IS ACCOUNTED FOR BY USING diff_norm <= 1e-12test = np.array([[2.0,1.0], [2.0,1.0]])f_test_res, g_test_res = rank_approx(test, 1)print("F_test")print(test)print("Approx F_test with rank: 1")f_approx = np.matmul(f_test_res, g_test_res.T)print(f_approx)diff_norm = np.linalg.norm(test - f_approx)print("FROB NORM OF DIFF: " + str(diff_norm))assert diff_norm <= 1e-12test[1][1] += 0.1f_test_res_2, g_test_res_2 = rank_approx(test, 1)print("\nF_test_2")print(test)print("Approx F_test_2 with rank: 1")f_approx = np.matmul(f_test_res_2, g_test_res_2.T)print(f_approx)diff_norm = np.linalg.norm(f_approx - test)print("FROB NORM OF DIFF: " + str(diff_norm))assert diff_norm <= 0.07f_test_res_2, g_test_res_2 = rank_approx(test, 2)print("Approx F_test_2 with rank: 2")f_approx = np.matmul(f_test_res_2, g_test_res_2.T)print(f_approx)diff_norm = np.linalg.norm(test - f_approx)print("FROB NORM OF DIFF: " + str(diff_norm))assert diff_norm <= 1e-12# CELL TO VALIDATE CONV_REG AND CONV_APPROX FUNCTIONS WITH AN EXAMPLE# THIS CELL CHECKS WHEN RANK OF F IS 1A = np.random.randn(10,10)test_f = np.array([[1.0,1.0], [1.0,1.0]])conv_reg_A = conv_reg(test_f, A)# Check ensuring conv_reg function is working properlyfor i in range(np.shape(conv_reg_A)[0]):    for j in range(np.shape(conv_reg_A)[1]):        check = A[i][j] + A[i][j+1] + A[i+1][j] + A[i+1][j+1]        assert check == conv_reg_A[i][j]        conv_approx_A_1 = conv_approx(test_f, A, 1)f, g = rank_approx(test_f, 1)diff_norm = np.linalg.norm(conv_approx_A_1 - conv_reg_A)print("FROB NORM OF DIFF BETWEEN REG AND APPROX CONV WHERE EXACT APPROX IS POSSIBLE: " + str(diff_norm))# NOTE THAT DUE TO FLOATING POINT ERROR THERE MAY BE SLIGHT# ERRORS FROM THE EXACT BUT WITH SUCH A SMALL ERROR WE CAN# JUST CONSIDER THE MATRICES EQUAL AND THE FUNCTIONS VALIDassert diff_norm <= 1e-10# CELL TO VALIDATE CONV_REG AND CONV_APPROX FUNCTIONS WITH AN EXAMPLE# THIS CELL CHECKS WHEN RANK OF F IS 1A = np.random.randn(10,10)test_f = np.array([[1.0,1.0], [1.0,1.1]])conv_reg_A = conv_reg(test_f, A)# Check ensuring conv_reg function is working properlyfor i in range(np.shape(conv_reg_A)[0]):    for j in range(np.shape(conv_reg_A)[1]):        check = A[i][j] + A[i][j+1] + A[i+1][j] + A[i+1][j+1] * 1.1        assert check == conv_reg_A[i][j]        conv_approx_A_1 = conv_approx(test_f, A, 2)f, g = rank_approx(test_f, 2)diff_norm = np.linalg.norm(conv_approx_A_1 - conv_reg_A)print("FROB NORM OF DIFF BETWEEN REG AND APPROX CONV WHERE EXACT APPROX IS POSSIBLE: " + str(diff_norm))# NOTE THAT DUE TO FLOATING POINT ERROR THERE MAY BE SLIGHT# ERRORS FROM THE EXACT BUT WITH SUCH A SMALL ERROR WE CAN# JUST CONSIDER THE MATRICES EQUAL AND THE FUNCTIONS VALIDassert diff_norm <= 1e-10class CNNModel(torch.nn.Module):    def __init__(self, channel_count, classes_count):        super(CNNModel, self).__init__()                self.conv1 = torch.nn.Conv2d(channel_count, channel_count, (5,5), padding = 'same')        self.activation1 = torch.nn.ReLU()        self.pool1 = torch.nn.MaxPool2d(POOL_SIZE_PER, POOL_STRIDE)                self.conv2 = torch.nn.Conv2d(channel_count, channel_count, (5,5), padding = 'same')        self.activation2 = torch.nn.ReLU()        self.pool2 = torch.nn.MaxPool2d(POOL_SIZE_PER, POOL_STRIDE)                in_flattened_size = int(image_h) * int(image_w)//16        out_flattened_size = in_flattened_size//2        self.linear1 = torch.nn.Linear(in_flattened_size, out_flattened_size)        self.activation3 = torch.nn.ReLU()                self.linear2 = torch.nn.Linear(out_flattened_size, 10)            def forward(self, batch_input):        batch_layer_1_res = self.pool1(self.activation1(self.conv1(batch_input.float())))        batch_layer_2_res = self.pool2(self.activation2(self.conv2(batch_layer_1_res)))        batch_layer_3_res = self.activation3(self.linear1(torch.flatten(batch_layer_2_res, start_dim = 1)))        res_logits = self.linear2(batch_layer_3_res)        return res_logitsmodel = CNNModel(1, total_classes)adam_optimizer = torch.optim.Adam(model.parameters(), lr=LR_START)ceLoss = torch.nn.CrossEntropyLoss()loss_acc_history = np.zeros((16,E))def train_model(epoch: int):    order = np.arange(total_train_images, dtype = int)    np.random.shuffle(order)    folder_indexes_order = np.floor_divide(order, images_per_class_train)    image_indexes_order = order - (folder_indexes_order * images_per_class_train)    total_loss = 0    total_correct = 0    for curr_round in range(TRAIN_ROUNDS):        start_index = curr_round * BATCH_SIZE        end_index = min(start_index + BATCH_SIZE, total_train_images)        batch_train_tensor = create_grayscale_batch(            True,             folder_indexes_order[start_index:end_index],            image_indexes_order[start_index:end_index]        )        batch_truth_tensor = create_ground_truth_batch(folder_indexes_order[start_index:end_index])        batch_res = model(batch_train_tensor)        loss = ceLoss(batch_res, batch_truth_tensor)                adam_optimizer.zero_grad()        loss.backward()        adam_optimizer.step()        total_loss += float(loss)        total_correct += torch.sum(torch.argmax(batch_res, dim = 1).int() == batch_truth_tensor.int())                if curr_round%500 == 0:            print("Curr Round: " + str(curr_round) + " train loss: " + str(total_loss))            print("Curr Round: " + str(curr_round) + " train accuracy: " + str(float(total_correct)/float(total_train_images)))            epoch_acc = float(total_correct)/float(total_train_images)    loss_acc_history[0][epoch] = total_loss    loss_acc_history[1][epoch] = epoch_acc    print("POST EPOCH: " + str(epoch) + " train loss: " + str(total_loss))    print("POST EPOCH: " + str(epoch) + " train accuracy: " + str(epoch_acc))    def test_model(epoch: int, rank_n: int):    start_time = time.time()    F1 = (torch.clone(model.conv1.weight).detach().numpy())[0][0]    B1 = torch.clone(model.conv1.bias).detach().numpy()[0]    left_matrices_1, right_matrices_1 = conv_approx_create_matrices(F1, image_h, image_w, rank_n)    F2 = np.squeeze(torch.clone(model.conv2.weight).detach().numpy())    B2 = torch.clone(model.conv2.bias).detach().numpy()[0]    left_matrices_2, right_matrices_2 = conv_approx_create_matrices(F2, image_h//2, image_w//2, rank_n)    w1 = torch.clone(model.linear1.weight).detach().numpy()    lb1 = np.reshape(torch.clone(model.linear1.bias).detach().numpy(), (-1,1))    w2 = torch.clone(model.linear2.weight).detach().numpy()    lb2 = np.reshape(torch.clone(model.linear2.bias).detach().numpy(), (-1,1))    all_test_images_list = np.arange(total_test_images)    all_test_images_folders = np.floor_divide(all_test_images_list, images_per_class_test)    all_test_images_indexes = all_test_images_list - (all_test_images_folders * images_per_class_test)    all_test_images = create_grayscale_batch(False, all_test_images_folders, all_test_images_indexes).numpy()        testing_version = " REGULAR CONVOLUTION "    if rank_n:        testing_version = " APPROX CONVOLUTION WITH RANK: " + str(rank_n) + " "    storage_index = 4 + (2 * rank_n)            total_correct = 0        for img_number in range(total_test_images):        curr_img = np.squeeze(all_test_images[img_number], axis = 0)        if rank_n == -1:            """            c1 = model.conv1(torch.tensor(all_test_images[img_number]).float())            a1 = model.activation1(c1)            p1 = model.pool1(a1)            c2 = model.conv2(p1)            a2 = model.activation2(c2)            p2 = model.pool2(a2)            l1 = model.linear1(torch.flatten(p2,start_dim=0))            a3 = model.activation3(l1)            l2 = model.linear2(a3)            print(p2)            print(l1)            print(a3)            print(l2)            """            logits = model(torch.tensor(all_test_images[img_number]))            pred_class = torch.argmax(logits)        else:            logits = np_process_image(curr_img, F1, F2, B1, B2,                                      left_matrices_1, right_matrices_1,                                       left_matrices_2, right_matrices_2,                                       POOL_SIZE_PER, POOL_STRIDE,                                       w1, w2, lb1, lb2, rank_n)            pred_class = np.argmax(logits)        true_class = all_test_images_folders[img_number]        if int(pred_class) == int(true_class):            total_correct += 1                    if img_number%5000 == 0:            print("Image: " + str(img_number) + testing_version + str(float(total_correct)/float(total_test_images)))        end_time = time.time()    time_taken = end_time - start_time    epoch_acc = float(total_correct)/float(total_test_images)    loss_acc_history[storage_index][epoch] = epoch_acc    loss_acc_history[storage_index + 1][epoch] = time_taken    print(time_taken)    print("POST EPOCH: " + str(epoch) + testing_version + "TESTING ACCURACY: " + str(epoch_acc))        for epoch in range(E):    train_model(epoch)    test_model(epoch,-1)    test_model(epoch,0)    test_model(epoch,1)    test_model(epoch,2)    test_model(epoch,3)    test_model(epoch,4)    test_model(epoch,5)    np.savetxt("loss_acc_time_data_" + str(total_classes) + ".txt", loss_acc_history)        